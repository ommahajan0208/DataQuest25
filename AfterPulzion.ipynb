{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cf0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18153, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ASI_category</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>Soil_Temperature</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Gusts</th>\n",
       "      <th>...</th>\n",
       "      <th>Surface_Pressure</th>\n",
       "      <th>Relative_Humidity</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Dew_Point</th>\n",
       "      <th>Sunshine_Duration</th>\n",
       "      <th>Cloud_Cover</th>\n",
       "      <th>Precipitation_Hours</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Weather_Code</th>\n",
       "      <th>Daylight_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19554</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.931231</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757673</td>\n",
       "      <td>0.879671</td>\n",
       "      <td>0.179293</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538056</td>\n",
       "      <td>55</td>\n",
       "      <td>0.546243</td>\n",
       "      <td>17.564597</td>\n",
       "      <td>53252.08</td>\n",
       "      <td>12.136192</td>\n",
       "      <td>1</td>\n",
       "      <td>176.459082</td>\n",
       "      <td>51</td>\n",
       "      <td>58772.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25205</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.566323</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291448</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.588384</td>\n",
       "      <td>0.532172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568475</td>\n",
       "      <td>88</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>5.692134</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.901341</td>\n",
       "      <td>16</td>\n",
       "      <td>232.433005</td>\n",
       "      <td>61</td>\n",
       "      <td>28143.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771</td>\n",
       "      <td>Poor</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277340</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.189008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706520</td>\n",
       "      <td>78</td>\n",
       "      <td>0.791908</td>\n",
       "      <td>-25.264420</td>\n",
       "      <td>30213.79</td>\n",
       "      <td>18.859670</td>\n",
       "      <td>0</td>\n",
       "      <td>44.688600</td>\n",
       "      <td>3</td>\n",
       "      <td>34621.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.717541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635669</td>\n",
       "      <td>0.796709</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>57</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>5.913865</td>\n",
       "      <td>44627.21</td>\n",
       "      <td>38.759757</td>\n",
       "      <td>0</td>\n",
       "      <td>333.640418</td>\n",
       "      <td>3</td>\n",
       "      <td>59192.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14036</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.827170</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743855</td>\n",
       "      <td>0.781282</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.391421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546378</td>\n",
       "      <td>50</td>\n",
       "      <td>0.459538</td>\n",
       "      <td>9.661455</td>\n",
       "      <td>45267.17</td>\n",
       "      <td>60.058955</td>\n",
       "      <td>1</td>\n",
       "      <td>86.996954</td>\n",
       "      <td>51</td>\n",
       "      <td>59956.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID ASI_category  Temperature  Precipitation  Rainfall  Snowfall  \\\n",
       "0  19554     Moderate     0.931231       0.000912  0.000912       0.0   \n",
       "1  25205     Moderate     0.566323       0.096715  0.096715       0.0   \n",
       "2    771         Poor     0.018033       0.000000  0.000000       0.0   \n",
       "3   1976         Good     0.717541       0.000000  0.000000       0.0   \n",
       "4  14036     Moderate     0.827170       0.001825  0.001825       0.0   \n",
       "\n",
       "   Soil_Temperature  Radiation  Wind_Speed  Wind_Gusts  ...  Surface_Pressure  \\\n",
       "0          0.757673   0.879671    0.179293    0.193029  ...          0.538056   \n",
       "1          0.291448   0.008913    0.588384    0.532172  ...          0.568475   \n",
       "2          0.000000   0.277340    0.247475    0.189008  ...          0.706520   \n",
       "3          0.635669   0.796709    0.123737    0.134048  ...          0.547500   \n",
       "4          0.743855   0.781282    0.343434    0.391421  ...          0.546378   \n",
       "\n",
       "   Relative_Humidity  Soil_Moisture  Dew_Point  Sunshine_Duration  \\\n",
       "0                 55       0.546243  17.564597           53252.08   \n",
       "1                 88       0.557803   5.692134               0.00   \n",
       "2                 78       0.791908 -25.264420           30213.79   \n",
       "3                 57       0.473988   5.913865           44627.21   \n",
       "4                 50       0.459538   9.661455           45267.17   \n",
       "\n",
       "   Cloud_Cover  Precipitation_Hours  Wind_Direction  Weather_Code  \\\n",
       "0    12.136192                    1      176.459082            51   \n",
       "1    91.901341                   16      232.433005            61   \n",
       "2    18.859670                    0       44.688600             3   \n",
       "3    38.759757                    0      333.640418             3   \n",
       "4    60.058955                    1       86.996954            51   \n",
       "\n",
       "   Daylight_Duration  \n",
       "0           58772.52  \n",
       "1           28143.12  \n",
       "2           34621.43  \n",
       "3           59192.17  \n",
       "4           59956.03  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "# test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957f44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18153 entries, 0 to 18152\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   18153 non-null  int64  \n",
      " 1   ASI_category         18153 non-null  object \n",
      " 2   Temperature          18153 non-null  float64\n",
      " 3   Precipitation        18153 non-null  float64\n",
      " 4   Rainfall             18153 non-null  float64\n",
      " 5   Snowfall             18153 non-null  float64\n",
      " 6   Soil_Temperature     18153 non-null  float64\n",
      " 7   Radiation            18153 non-null  float64\n",
      " 8   Wind_Speed           18153 non-null  float64\n",
      " 9   Wind_Gusts           18153 non-null  float64\n",
      " 10  Pressure_MSL         18153 non-null  float64\n",
      " 11  Surface_Pressure     18153 non-null  float64\n",
      " 12  Relative_Humidity    18153 non-null  int64  \n",
      " 13  Soil_Moisture        18153 non-null  float64\n",
      " 14  Dew_Point            18153 non-null  float64\n",
      " 15  Sunshine_Duration    18153 non-null  float64\n",
      " 16  Cloud_Cover          18153 non-null  float64\n",
      " 17  Precipitation_Hours  18153 non-null  int64  \n",
      " 18  Wind_Direction       18153 non-null  float64\n",
      " 19  Weather_Code         18153 non-null  int64  \n",
      " 20  Daylight_Duration    18153 non-null  float64\n",
      "dtypes: float64(16), int64(4), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a3d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reduce_memory_usage(df):\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"Initial memory usage: {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type == object:\n",
    "            num_unique = df[col].nunique()\n",
    "            num_total = len(df[col])\n",
    "            if num_unique / num_total < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "        \n",
    "        elif col_type.name.startswith('int'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "\n",
    "        elif col_type.name.startswith('float'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"Optimized memory usage: {end_mem:.2f} MB\")\n",
    "    print(f\"Reduced by {100 * (start_mem - end_mem) / start_mem:.1f}%\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08318dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory usage: 3.74 MB\n",
      "Optimized memory usage: 1.35 MB\n",
      "Reduced by 63.8%\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "df_a = reduce_memory_usage(df)\n",
    "# (df- df_a).abs().sum().sum()\n",
    "import numpy as np\n",
    "\n",
    "# Select only numeric columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "diffs = (df[num_cols] - df_a[num_cols]).abs().sum()\n",
    "print(diffs[diffs > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0cf373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14522, 19) (3631, 19)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop ID and separate target\n",
    "X = df_a.drop(columns=['ASI_category', 'ID'])\n",
    "y = df_a['ASI_category']\n",
    "\n",
    "# If target is categorical text (e.g. Good, Moderate, Poor)\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad4db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# --- XGBoost ---\n",
    "best_xgb = XGBClassifier(\n",
    "    n_estimators=528,\n",
    "    learning_rate=0.06533478035634971, \n",
    "    max_depth=7, \n",
    "    subsample=0.5921834617441386, \n",
    "    colsample_bytree=0.6340862288557617, \n",
    "    gamma=1.399534210191034, \n",
    "    min_child_weight=3,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- LightGBM ---\n",
    "best_lgbm = LGBMClassifier(\n",
    "    n_estimators=255, \n",
    "    learning_rate=0.07817378543966169, \n",
    "    num_leaves=34, \n",
    "    max_depth=12, \n",
    "    subsample=0.7944500973942142, \n",
    "    colsample_bytree=0.9574183959836607, \n",
    "    reg_alpha=1.2227075268899349e-05, \n",
    "    reg_lambda=0.020009711326624165, \n",
    "    min_child_samples=18,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Random Forest ---\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=450,\n",
    "    max_depth=9,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    criterion=\"log_loss\",\n",
    "    max_features=0.7,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Soft Voting Ensemble ---\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgb\", best_xgb),\n",
    "        (\"lgbm\", best_lgbm),\n",
    "        (\"rf\", best_rf)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[0.001, 0.95, 0.46], \n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b913701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Voting Ensemble (XGB + LGBM + RF) Performance:\n",
      "Training Accuracy : 1.0000\n",
      "Validation Accuracy: 0.9427\n",
      "Training F1 Score  : 1.0000\n",
      "Validation F1 Score: 0.9216\n",
      "Œî F1 Gap           : 0.0784\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       628\n",
      "           1       0.95      0.97      0.96      2546\n",
      "           2       0.92      0.89      0.91       457\n",
      "\n",
      "    accuracy                           0.94      3631\n",
      "   macro avg       0.93      0.92      0.92      3631\n",
      "weighted avg       0.94      0.94      0.94      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "# Train ensemble\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_preds = voting_clf.predict(X_train)\n",
    "val_preds = voting_clf.predict(X_val)\n",
    "\n",
    "# Metrics\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average=\"macro\")\n",
    "val_f1 = f1_score(y_val, val_preds, average=\"macro\")\n",
    "\n",
    "print(\"\\n‚úÖ Voting Ensemble (XGB + LGBM + RF) Performance:\")\n",
    "print(f\"Training Accuracy : {train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Training F1 Score  : {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "print(f\"Œî F1 Gap           : {abs(train_f1 - val_f1):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c560939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3847\n",
      "[LightGBM] [Info] Number of data points in the train set: 14522, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.755382\n",
      "[LightGBM] [Info] Start training from score -0.355142\n",
      "[LightGBM] [Info] Start training from score -2.070802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.156307\n",
      "\n",
      "‚úÖ Ensemble Validation Accuracy: 0.9405\n",
      "‚úÖ Ensemble Validation F1 Score: 0.9184\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       628\n",
      "           1       0.95      0.96      0.96      2546\n",
      "           2       0.92      0.88      0.90       457\n",
      "\n",
      "    accuracy                           0.94      3631\n",
      "   macro avg       0.92      0.91      0.92      3631\n",
      "weighted avg       0.94      0.94      0.94      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import numpy as np\n",
    "\n",
    "# --- Train XGB and LGBM individually (with early stopping) ---\n",
    "best_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Train Random Forest normally ---\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# --- Manual weighted soft voting ensemble ---\n",
    "xgb_preds = best_xgb.predict_proba(X_val)\n",
    "lgbm_preds = best_lgbm.predict_proba(X_val)\n",
    "rf_preds  = best_rf.predict_proba(X_val)\n",
    "\n",
    "# Ensemble weights\n",
    "weights = [0.3, 0.6, 0.4]\n",
    "\n",
    "# Weighted average of probabilities\n",
    "final_probs = (\n",
    "    weights[0] * xgb_preds +\n",
    "    weights[1] * lgbm_preds +\n",
    "    weights[2] * rf_preds\n",
    ")\n",
    "\n",
    "# Final predictions\n",
    "val_preds = np.argmax(final_probs, axis=1)\n",
    "\n",
    "# --- Evaluate ---\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "val_f1  = f1_score(y_val, val_preds, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Ensemble Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"‚úÖ Ensemble Validation F1 Score: {val_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4092539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Best weights found: (np.float64(0.7000000000000001), np.float64(0.8), np.float64(0.30000000000000004)) | F1 = 0.9202\n",
      "\n",
      "‚úÖ Tuned Ensemble Accuracy: 0.9416\n",
      "‚úÖ Tuned Ensemble F1 Score: 0.9202\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       628\n",
      "           1       0.95      0.96      0.96      2546\n",
      "           2       0.92      0.89      0.91       457\n",
      "\n",
      "    accuracy                           0.94      3631\n",
      "   macro avg       0.93      0.91      0.92      3631\n",
      "weighted avg       0.94      0.94      0.94      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Grid search for best ensemble weights (optional boost) ---\n",
    "from itertools import product\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "xgb_p = best_xgb.predict_proba(X_val)\n",
    "lgbm_p = best_lgbm.predict_proba(X_val)\n",
    "rf_p   = best_rf.predict_proba(X_val)\n",
    "\n",
    "grid = np.arange(0.1, 1.1, 0.1)\n",
    "best_f1, best_w = 0, None\n",
    "\n",
    "for w1, w2, w3 in product(grid, repeat=3):\n",
    "    wsum = w1 + w2 + w3\n",
    "    probs = (w1*xgb_p + w2*lgbm_p + w3*rf_p) / wsum\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    f1 = f1_score(y_val, preds, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_w = f1, (w1, w2, w3)\n",
    "\n",
    "print(f\"üî• Best weights found: {best_w} | F1 = {best_f1:.4f}\")\n",
    "\n",
    "# --- Re-evaluate using best weights ---\n",
    "final_probs = (\n",
    "    best_w[0] * xgb_p +\n",
    "    best_w[1] * lgbm_p +\n",
    "    best_w[2] * rf_p\n",
    ") / sum(best_w)\n",
    "\n",
    "val_preds = np.argmax(final_probs, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "val_f1  = f1_score(y_val, val_preds, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Tuned Ensemble Accuracy: {val_acc:.4f}\")\n",
    "print(f\"‚úÖ Tuned Ensemble F1 Score: {val_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af3c23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Re-training base models with refined parameters...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3847\n",
      "[LightGBM] [Info] Number of data points in the train set: 14522, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.755382\n",
      "[LightGBM] [Info] Start training from score -0.355142\n",
      "[LightGBM] [Info] Start training from score -2.070802\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.157536\n",
      "‚úÖ Base models retrained successfully.\n",
      "\n",
      "‚öôÔ∏è Searching for best ensemble weights...\n",
      "üî• Best weights found: (np.float64(0.7000000000000001), np.float64(0.1), np.float64(0.1)) | F1 = 0.9204\n",
      "\n",
      "‚úÖ Tuned Ensemble Accuracy: 0.9419\n",
      "‚úÖ Tuned Ensemble F1 Score: 0.9204\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       628\n",
      "           1       0.95      0.96      0.96      2546\n",
      "           2       0.92      0.89      0.90       457\n",
      "\n",
      "    accuracy                           0.94      3631\n",
      "   macro avg       0.93      0.92      0.92      3631\n",
      "weighted avg       0.94      0.94      0.94      3631\n",
      "\n",
      "\n",
      "üöÄ Training meta-stacking layer (Logistic Regression)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Stacked Model Accuracy: 0.9394\n",
      "üèÅ Stacked Model F1 Score: 0.9165\n",
      "\n",
      "Classification Report (Stacked):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       628\n",
      "           1       0.95      0.97      0.96      2546\n",
      "           2       0.92      0.88      0.90       457\n",
      "\n",
      "    accuracy                           0.94      3631\n",
      "   macro avg       0.93      0.91      0.92      3631\n",
      "weighted avg       0.94      0.94      0.94      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% -------------------------------------------\n",
    "# üî• Improved Ensemble Training & Optimization\n",
    "# ---------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Re-tune & retrain base models ---\n",
    "\n",
    "print(\"üîß Re-training base models with refined parameters...\")\n",
    "\n",
    "# XGBoost\n",
    "best_xgb.set_params(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.045,\n",
    "    max_depth=8,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "best_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "best_lgbm.set_params(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.055,\n",
    "    num_leaves=40,\n",
    "    max_depth=14,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.95\n",
    ")\n",
    "best_lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(stopping_rounds=80), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "best_rf.set_params(\n",
    "    n_estimators=600,\n",
    "    max_depth=10,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.8\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Base models retrained successfully.\\n\")\n",
    "\n",
    "# --- Step 2: Generate validation probabilities ---\n",
    "xgb_p = best_xgb.predict_proba(X_val)\n",
    "lgbm_p = best_lgbm.predict_proba(X_val)\n",
    "rf_p   = best_rf.predict_proba(X_val)\n",
    "\n",
    "# --- Step 3: Grid search for best weights ---\n",
    "print(\"‚öôÔ∏è Searching for best ensemble weights...\")\n",
    "grid = np.arange(0.1, 1.1, 0.1)\n",
    "best_f1, best_w = 0, None\n",
    "\n",
    "for w1, w2, w3 in product(grid, repeat=3):\n",
    "    wsum = w1 + w2 + w3\n",
    "    probs = (w1*xgb_p + w2*lgbm_p + w3*rf_p) / wsum\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    f1 = f1_score(y_val, preds, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_w = f1, (w1, w2, w3)\n",
    "\n",
    "print(f\"üî• Best weights found: {best_w} | F1 = {best_f1:.4f}\")\n",
    "\n",
    "# --- Step 4: Evaluate tuned ensemble ---\n",
    "final_probs = (\n",
    "    best_w[0]*xgb_p +\n",
    "    best_w[1]*lgbm_p +\n",
    "    best_w[2]*rf_p\n",
    ") / sum(best_w)\n",
    "\n",
    "val_preds = np.argmax(final_probs, axis=1)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "val_f1  = f1_score(y_val, val_preds, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Tuned Ensemble Accuracy: {val_acc:.4f}\")\n",
    "print(f\"‚úÖ Tuned Ensemble F1 Score: {val_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds))\n",
    "\n",
    "# --- Step 5 (Optional): Meta-stacking for extra boost ---\n",
    "print(\"\\nüöÄ Training meta-stacking layer (Logistic Regression)...\")\n",
    "\n",
    "stack_X = np.hstack([\n",
    "    best_xgb.predict_proba(X_val),\n",
    "    best_lgbm.predict_proba(X_val),\n",
    "    best_rf.predict_proba(X_val)\n",
    "])\n",
    "\n",
    "meta = LogisticRegression(max_iter=300, multi_class='multinomial', solver='lbfgs')\n",
    "meta.fit(stack_X, y_val)\n",
    "\n",
    "stack_preds = np.argmax(meta.predict_proba(stack_X), axis=1)\n",
    "stack_acc = accuracy_score(y_val, stack_preds)\n",
    "stack_f1 = f1_score(y_val, stack_preds, average='macro')\n",
    "\n",
    "print(f\"\\nüèÅ Stacked Model Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"üèÅ Stacked Model F1 Score: {stack_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Stacked):\\n\", classification_report(y_val, stack_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b73923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Calibrating base model probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Calibrated Meta-XGB Accuracy: 0.9546\n",
      "üèÅ Calibrated Meta-XGB F1 Score: 0.9389\n",
      "\n",
      "Classification Report (Calibrated Meta-XGB):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       628\n",
      "           1       0.96      0.97      0.97      2546\n",
      "           2       0.94      0.93      0.94       457\n",
      "\n",
      "    accuracy                           0.95      3631\n",
      "   macro avg       0.94      0.94      0.94      3631\n",
      "weighted avg       0.95      0.95      0.95      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% -------------------------------------------\n",
    "# üöÄ Final Boost: Calibrated + Meta-XGB Ensemble\n",
    "# ----------------------------------------------\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"üîß Calibrating base model probabilities...\")\n",
    "\n",
    "# 1Ô∏è‚É£ Calibrate base models (using validation data)\n",
    "cal_xgb = CalibratedClassifierCV(best_xgb, method=\"isotonic\", cv=\"prefit\")\n",
    "cal_lgbm = CalibratedClassifierCV(best_lgbm, method=\"isotonic\", cv=\"prefit\")\n",
    "cal_rf = CalibratedClassifierCV(best_rf, method=\"isotonic\", cv=\"prefit\")\n",
    "\n",
    "cal_xgb.fit(X_val, y_val)\n",
    "cal_lgbm.fit(X_val, y_val)\n",
    "cal_rf.fit(X_val, y_val)\n",
    "\n",
    "# 2Ô∏è‚É£ Generate calibrated probabilities\n",
    "xgb_p = cal_xgb.predict_proba(X_val)\n",
    "lgbm_p = cal_lgbm.predict_proba(X_val)\n",
    "rf_p   = cal_rf.predict_proba(X_val)\n",
    "\n",
    "# 3Ô∏è‚É£ Stack features for meta-model\n",
    "stack_X = np.hstack([xgb_p, lgbm_p, rf_p])\n",
    "\n",
    "# 4Ô∏è‚É£ Train a small XGB meta-learner\n",
    "meta_xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "meta_xgb.fit(stack_X, y_val)\n",
    "\n",
    "# 5Ô∏è‚É£ Evaluate meta-XGB on validation\n",
    "stack_preds = np.argmax(meta_xgb.predict_proba(stack_X), axis=1)\n",
    "stack_acc = accuracy_score(y_val, stack_preds)\n",
    "stack_f1 = f1_score(y_val, stack_preds, average=\"macro\")\n",
    "\n",
    "print(f\"\\nüèÅ Calibrated Meta-XGB Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"üèÅ Calibrated Meta-XGB F1 Score: {stack_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Calibrated Meta-XGB):\\n\", classification_report(y_val, stack_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951a1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae16959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running Advanced Ensemble Refinement...\n",
      "üîç Expanded feature space from 19 to 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Meta-LogReg (Poly Features) Accuracy: 0.9576\n",
      "üèÅ Meta-LogReg (Poly Features) F1 Score: 0.9424\n",
      "\n",
      "Classification Report (Meta-LogReg):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       628\n",
      "           1       0.97      0.97      0.97      2546\n",
      "           2       0.94      0.93      0.93       457\n",
      "\n",
      "    accuracy                           0.96      3631\n",
      "   macro avg       0.95      0.94      0.94      3631\n",
      "weighted avg       0.96      0.96      0.96      3631\n",
      "\n",
      "üß© Adding 2980 confident pseudo-labeled samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ommah\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Pseudo-Labeled Meta Accuracy: 0.9562\n",
      "üöÄ Pseudo-Labeled Meta F1 Score: 0.9401\n",
      "\n",
      "Classification Report (Pseudo-Labeled Meta):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       628\n",
      "           1       0.96      0.97      0.97      2546\n",
      "           2       0.94      0.92      0.93       457\n",
      "\n",
      "    accuracy                           0.96      3631\n",
      "   macro avg       0.95      0.93      0.94      3631\n",
      "weighted avg       0.96      0.96      0.96      3631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% --------------------------------------------------------\n",
    "# ‚öóÔ∏è Experimental Refinement: Meta-Feature Engineering + Pseudo-Labeling (Fixed Indexing)\n",
    "# ------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "print(\"üß™ Running Advanced Ensemble Refinement...\")\n",
    "\n",
    "# 1Ô∏è‚É£ --- Feature Interaction Expansion ---\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "\n",
    "# Normalize to keep stability\n",
    "scaler = StandardScaler()\n",
    "X_train_poly = scaler.fit_transform(X_train_poly)\n",
    "X_val_poly = scaler.transform(X_val_poly)\n",
    "\n",
    "print(f\"üîç Expanded feature space from {X_train.shape[1]} to {X_train_poly.shape[1]}\")\n",
    "\n",
    "# 2Ô∏è‚É£ --- Generate predictions from calibrated models ---\n",
    "xgb_p = cal_xgb.predict_proba(X_val)\n",
    "lgbm_p = cal_lgbm.predict_proba(X_val)\n",
    "rf_p   = cal_rf.predict_proba(X_val)\n",
    "\n",
    "# 3Ô∏è‚É£ --- Meta features combining model probs and engineered features ---\n",
    "meta_features = np.hstack([xgb_p, lgbm_p, rf_p, X_val_poly])\n",
    "\n",
    "# 4Ô∏è‚É£ --- Meta model with L2-regularized Logistic Regression ---\n",
    "meta_lr = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    C=2.0,\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "meta_lr.fit(meta_features, y_val)\n",
    "meta_preds = meta_lr.predict(meta_features)\n",
    "\n",
    "meta_acc = accuracy_score(y_val, meta_preds)\n",
    "meta_f1 = f1_score(y_val, meta_preds, average=\"macro\")\n",
    "\n",
    "print(f\"\\nüèÅ Meta-LogReg (Poly Features) Accuracy: {meta_acc:.4f}\")\n",
    "print(f\"üèÅ Meta-LogReg (Poly Features) F1 Score: {meta_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Meta-LogReg):\\n\", classification_report(y_val, meta_preds))\n",
    "\n",
    "# 5Ô∏è‚É£ --- Semi-supervised pseudo-labeling ---\n",
    "confidence = np.max(meta_lr.predict_proba(meta_features), axis=1)\n",
    "threshold = 0.95\n",
    "pseudo_idx = np.where(confidence >= threshold)[0]\n",
    "\n",
    "if len(pseudo_idx) > 0:\n",
    "    print(f\"üß© Adding {len(pseudo_idx)} confident pseudo-labeled samples...\")\n",
    "\n",
    "    # ‚úÖ Use .iloc for proper row selection\n",
    "    X_val_sel = X_val.iloc[pseudo_idx]\n",
    "    X_val_poly_sel = X_val_poly[pseudo_idx]\n",
    "\n",
    "    val_aug = np.hstack([\n",
    "        cal_xgb.predict_proba(X_val_sel),\n",
    "        cal_lgbm.predict_proba(X_val_sel),\n",
    "        cal_rf.predict_proba(X_val_sel),\n",
    "        X_val_poly_sel\n",
    "    ])\n",
    "\n",
    "    X_aug = np.vstack([meta_features, val_aug])\n",
    "    y_aug = np.concatenate([y_val.to_numpy(), y_val.to_numpy()[pseudo_idx]])\n",
    "\n",
    "    meta_lr.fit(X_aug, y_aug)\n",
    "\n",
    "    final_preds = meta_lr.predict(meta_features)\n",
    "\n",
    "    final_acc = accuracy_score(y_val, final_preds)\n",
    "    final_f1 = f1_score(y_val, final_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"\\nüöÄ Pseudo-Labeled Meta Accuracy: {final_acc:.4f}\")\n",
    "    print(f\"üöÄ Pseudo-Labeled Meta F1 Score: {final_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Pseudo-Labeled Meta):\\n\",\n",
    "          classification_report(y_val, final_preds))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No pseudo-labels added ‚Äî model already very confident.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a8ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
